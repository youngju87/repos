# Quick Start - Attribution Modeling Lab

Get started with multi-touch attribution analysis in 10 minutes.

## Prerequisites

- Python 3.11+
- Virtual environment (recommended)

## Setup (5 minutes)

### 1. Navigate to Project

```bash
cd C:\Users\Justin\source\repos\attribution-modeling-lab
```

### 2. Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Mac/Linux
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

## Quick Start (5 minutes)

### Step 1: Generate Sample Data

```bash
python attribution_cli.py generate --journeys 1000 --conversion-rate 0.15
```

Output:
```
Generating 1,000 journeys...
  Target conversions: 150 (15.0%)
  Avg journey length: 4 touchpoints

âœ“ Generated 1,000 journeys
  Conversions: 150
  Total touchpoints: 4,287

Dataset Summary:
  Total Journeys:     1,000
  Conversions:        150 (15.0%)
  Total Revenue:      $24,850.00
  Total Cost:         $8,574.00
  ROI:                189.9%
```

### Step 2: Run Attribution Analysis

```bash
python attribution_cli.py analyze
```

This will:
- Train the data-driven model
- Run all 6 attribution models
- Save results for comparison

Output:
```
Running Attribution Analysis

âœ“ Loaded 1,000 journeys

Training data-driven model...
âœ“ Data-driven model trained on 1,000 journeys
  Channels analyzed: 12
  Conversion rate: 15.0%

Running attribution models on 150 converting journeys...
  â€¢ Last-Touch...
  â€¢ First-Touch...
  â€¢ Linear...
  â€¢ Time-Decay...
  â€¢ Position-Based...
  â€¢ Data-Driven...
âœ“ All models complete
```

### Step 3: Compare Models

```bash
python attribution_cli.py compare
```

See side-by-side comparison of how each model attributes revenue:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Channel                 â”‚ Cost     â”‚ Last-Touch  â”‚ First-Touch â”‚ Linear â”‚ Time-Decay  â”‚ Position-... â”‚ Data-Driven  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Paid Search - Brand     â”‚ $625     â”‚ $11,234     â”‚ $3,021      â”‚ $5,447 â”‚ $9,112      â”‚ $7,285       â”‚ $5,892       â”‚
â”‚ Display Ads             â”‚ $210     â”‚ $1,247      â”‚ $6,892      â”‚ $4,123 â”‚ $2,034      â”‚ $4,556       â”‚ $6,234       â”‚
â”‚ Email                   â”‚ $43      â”‚ $3,421      â”‚ $1,235      â”‚ $4,567 â”‚ $3,789      â”‚ $3,891       â”‚ $4,123       â”‚
â”‚ ...                     â”‚          â”‚             â”‚             â”‚        â”‚             â”‚              â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Model Agreement Score: 67%
âš  Moderate disagreement between models
```

### Step 4: View ROAS by Channel

```bash
python attribution_cli.py roas --model "Data-Driven"
```

See which channels have the best return on ad spend:

```
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rank â”‚ Channel             â”‚ Revenue   â”‚ Cost    â”‚ ROAS   â”‚ CPA     â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1    â”‚ Email               â”‚ $4,123    â”‚ $43     â”‚ 95.88x â”‚ $8.60   â”‚ ğŸŸ¢     â”‚
â”‚ 2    â”‚ Organic Search      â”‚ $3,456    â”‚ $0      â”‚ âˆ      â”‚ $0.00   â”‚ ğŸŸ¢     â”‚
â”‚ 3    â”‚ Display Ads         â”‚ $6,234    â”‚ $210    â”‚ 29.69x â”‚ $42.00  â”‚ ğŸŸ¢     â”‚
â”‚ 4    â”‚ Paid Search - Brand â”‚ $5,892    â”‚ $625    â”‚ 9.43x  â”‚ $125.00 â”‚ ğŸŸ¢     â”‚
â”‚ 5    â”‚ Social - Paid       â”‚ $2,145    â”‚ $384    â”‚ 5.59x  â”‚ $76.80  â”‚ ğŸŸ¢     â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŸ¢ Excellent (3.0x+)  ğŸŸ¡ Good (1.5x+)  ğŸ”´ Needs Improvement
```

### Step 5: Get Budget Recommendations

```bash
python attribution_cli.py recommendations
```

See where to reallocate budget:

```
Budget Recommendations

Based on Last-Touch vs Data-Driven comparison:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Display Ads                              â”‚
â”‚                                             â”‚
â”‚ ğŸ“ˆ INCREASE Budget                          â”‚
â”‚                                             â”‚
â”‚ Attribution Comparison:                     â”‚
â”‚   Last-Touch:         $1,247.00             â”‚
â”‚   Data-Driven:        $6,234.00             â”‚
â”‚   Difference:       +$4,987.00 (+400%)      â”‚
â”‚                                             â”‚
â”‚ Current Performance:                        â”‚
â”‚   ROAS: 29.69x                              â”‚
â”‚                                             â”‚
â”‚ Reason:                                     â”‚
â”‚   Data-driven shows 400% more value than    â”‚
â”‚   last-touch                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## All Available Commands

### Data Generation

```bash
# Generate custom dataset
python attribution_cli.py generate --journeys 5000 --conversion-rate 0.20 --avg-length 5
```

### Analysis

```bash
# Run attribution analysis
python attribution_cli.py analyze

# View overall summary
python attribution_cli.py summary
```

### Comparisons

```bash
# Compare all models
python attribution_cli.py compare

# View ROAS for specific model
python attribution_cli.py roas --model "Linear"
python attribution_cli.py roas --model "Last-Touch"
```

### Insights

```bash
# Show biggest disagreements across models
python attribution_cli.py disagreements

# Get budget recommendations
python attribution_cli.py recommendations

# Analyze specific journey
python attribution_cli.py journey
python attribution_cli.py journey --journey-id abc123
```

## Understanding the Output

### Model Agreement Score

- **80-100%**: Models strongly agree - any model will give similar insights
- **50-80%**: Moderate disagreement - compare models carefully
- **0-50%**: High disagreement - investigate why models differ

### ROAS (Return on Ad Spend)

- **3.0x+**: Excellent - keep investing
- **1.5-3.0x**: Good - solid performer
- **1.0-1.5x**: Breaking even - needs optimization
- **<1.0x**: Losing money - reduce or cut budget

### Attribution Models Explained

**Last-Touch**: All credit to final touchpoint
- Use when: Short sales cycles, direct response

**First-Touch**: All credit to first touchpoint
- Use when: Measuring awareness campaigns

**Linear**: Equal credit to all touchpoints
- Use when: All touchpoints equally important

**Time-Decay**: More credit to recent touchpoints
- Use when: Recency matters, longer sales cycles

**Position-Based**: 40% first, 40% last, 20% middle
- Use when: Balancing awareness and conversion

**Data-Driven**: ML-based credit allocation
- Use when: Large dataset, complex journeys, most accurate

## Sample Workflow

### Typical Analysis Flow

```bash
# 1. Generate data
python attribution_cli.py generate --journeys 2000

# 2. Run analysis
python attribution_cli.py analyze

# 3. View summary
python attribution_cli.py summary

# 4. Compare models
python attribution_cli.py compare

# 5. Check disagreements
python attribution_cli.py disagreements

# 6. Get recommendations
python attribution_cli.py recommendations

# 7. View ROAS
python attribution_cli.py roas --model "Data-Driven"
```

## Real-World Use Cases

### Use Case 1: Evaluate Display Advertising

**Question**: Is our display advertising working?

```bash
python attribution_cli.py roas --model "Data-Driven"
```

Look for "Display Ads" in the table:
- High ROAS in data-driven but low in last-touch â†’ Keep display (it's working for awareness)
- Low ROAS across all models â†’ Cut display budget

### Use Case 2: Optimize Email Marketing

**Question**: Should we invest more in email?

```bash
python attribution_cli.py recommendations
```

If email shows up with "INCREASE" â†’ Invest more
If email shows "DECREASE" â†’ Reduce spend

### Use Case 3: Justify Budget Decisions

**Question**: Prove to management that our attribution is correct

```bash
python attribution_cli.py compare
python attribution_cli.py disagreements
```

Show:
- Where models agree (reliable conclusions)
- Where models disagree (need more investigation)
- Data-driven vs last-touch differences

## Next Steps

1. **Use Real Data**: Replace sample generator with actual journey data
2. **Customize Models**: Adjust time-decay half-life, position-based weights
3. **Export Reports**: Save results to CSV/PDF
4. **Build Dashboard**: Create interactive Plotly dashboard
5. **Integrate with Analytics**: Connect to GA4, Adobe Analytics, etc.

## Troubleshooting

### "No data found. Run 'generate' first"

You need to generate data before running analysis:
```bash
python attribution_cli.py generate
```

### "Model not found"

Check available models with:
```bash
python attribution_cli.py compare
```

Use exact model name: "Last-Touch", "First-Touch", "Linear", "Time-Decay", "Position-Based", "Data-Driven"

### Low model agreement

This is normal! It means:
- Different models have different assumptions
- Some channels are harder to attribute (like display awareness)
- You should investigate the disagreements

---

**Time to first insights: ~10 minutes**

Start analyzing your attribution now!
